{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementations of the Stochastic Gradient Hamilton Monte Carlo Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Tiancheng Pan, Lingyu Zhou and Fan Zhu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this package, we followed and implemented the \"Stochastic Gradient Hamiltonian Monte Carlo\" algorithm, which was proposed by Tianqi Chen, Emily B. Fox and Carlos Guestrin (2014). To significantly reduce the computational complexity, this Hamilton Monte Carlo algorithm incorporates the stochastic gradient, which is computed on minibatchs of data with noise and counterbalances that noise by a friction term. The SGHMC algorithm was initially implemented in Python and then optimized through numba, Cython (C++) and multiprocessing. [Abstract on examples] The behaviors of SGHMC algorithm were examined on two examples compared to two other MCMC methods. [Briefly describe the tests] There is an up-to-date Github repository for our SGHMC codes at (https://github.com/TianchenPan/STA-663-Final-Project). The instructions of installation and explanation of this package are available in README file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Optimization for Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications to Simulated Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1]( Example1_a.png \"Figure 1\")\n",
    "<center>Figure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first simulation example, which is as mentioned as in the original paper, where $U(\\theta)=-2\\theta^2+\\theta^4$ and $\\nabla \\tilde{U}=\\nabla U + N(0,4)$. We set $\\hat{V}$ to be a 0 matrix with shape $(1,1)$, $\\epsilon$ equals to 0.1, and batch size equal to 1. The sample size is 1000 and the number of iteration is 2000. Finally, we have a very similar density plot to that in the original paper. Thus the algorithm we have is pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simualtion 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 2]( Example2_a.png \"Figure 2\")\n",
    "<center>Figure 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second simulation example, we choose the mixture normal distribution, where $x \\sim 0.5*N(\\mu_1,1)+0.5*N(\\mu_2,1)$, where $\\mu_1=-3, \\mu_2=3$.We set $\\hat{V}$ to be an identity matrix with shape $(2,2)$, $\\epsilon$ equals 0.1, and batch size equal to 1000. The sample size is 1000 and the number of iteration is 2000 again. The result is shown in figure 2, which is quite reasonable since the distribution is centered at $(3,-3)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications to Real Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis with Competing Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the comparative analysis, we want to focus on the same problem as simulation 1, since we have the exact density plot in the original paper. I want to compare our algorithms with `hmc` in the Pyhmc package, which is a standard HMC method, and `pystan` in the Pystan package, which is a no-U-turn implementation of HMC. For `hmc`, we set the sample size to be 1000, and for `pystan`, we set the number of iteration to be 2000. All the other parameters are set to be the default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 3]( comp_stan.png \"Figure 3\")\n",
    "<center>Figure 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 4]( comp_hmc.png \"Figure 4\")\n",
    "<center>Figure 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3 and Figure 4 are the density plot for the `pystan` and `pyhmc` with the same sample size or number of iteration as ourselves algorithm. As we can see, the density plot of `pyhmc` is significantly different from the original plot. The two peaks of density are not symmetric with the $\\theta=0$. Moreover, for the plot of `pystan`, it looks like the original plots, but it is less condense at two peaks and more condense at the nadir when $\\theta=0$. Admittedly, we do not change the default setting for both algorithm and the performance may be better if we choose a more reasonable parameter. Also, the running time for `sghmc` is longer than both of the above two. But it did show that `sghmc` did pretty well for the s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
